# log
output_path: "./Experiments/log_base"

# data
in_channels: 1
num_classes: 1 # must count the background class
threshold: 15
ours: True
ours_start: 200  # MSE warmup for first 200 epochs, then switch to SnakeSimpleLoss

# our loss
stepsz: 0.1
alpha: 0.0001
beta: 0.01
fltrstdev: 0.5
extparam: 1
nsteps: 10
ndims: 2
cropsz: [32,32]
dmax: 15
maxedgelength: 5
extgradfac: 2.0
    
# network
three_dimensional: False
m_channels: 32
n_convs: 2
n_levels: 3
dropout: 0.1
batch_norm: True
upsampling: "deconv"
pooling: "max"

# optimizer
lr: 0.001
weight_decay: 0.0001
lr_decay: True
lr_decay_factor: 0.001

# training
batch_size: 4
crop_size: [128,128]

# testing
crop_size_test: [128,128]
margin_size: [22,22]

# trainer
num_iters: 600  # Continue training beyond epoch 400
print_every: 10
valid_every: 50
save_every: 50
